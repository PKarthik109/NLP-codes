from nltk.tokenize import sent_tokenize,word_tokenize
EXAMPLE_TEXT = "understand"

print(sent_tokenize(EXAMPLE_TEXT))

print("\n \n")

print(word_tokenize(EXAMPLE_TEXT))