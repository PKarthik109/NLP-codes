from nltk.tokenize import word_tokenize
text= "natural Language Processing is exicitng ."
tokens =word_tokenize(text)
print(tokens)
