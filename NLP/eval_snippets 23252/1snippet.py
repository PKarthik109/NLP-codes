from nltk.tokenize import word_tokenize
text="natural language processing is exciting"
tokens=word_tokenize(text)
print(tokens)
